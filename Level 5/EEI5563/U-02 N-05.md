## Performance Metrics


## Clock Speed (Frequency)

- **Definition:** The fundamental rate at which the CPU's internal clock oscillates, measured in Hertz (Hz). A single Hz represents one cycle per second. Modern CPUs operate at speeds in the gigahertz range (GHz).
- **Significance:**
    - Dictates the basic pace at which a processor can execute instructions.
    - Higher clock speeds, within the same CPU architecture, often imply faster instruction processing.

## Instructions Per Cycle (IPC)

- **Definition:** The average number of instructions a processor can execute within a single clock cycle.
- **Significance:**
    - Measures the efficiency of the CPU's pipeline, which breaks down instructions into smaller stages.
    - A higher IPC means the processor is better at executing multiple instructions concurrently.
- **Factors Affecting IPC:**
    - **Instruction Dependencies:** Instructions that depend on the results of others can stall the pipeline, lowering IPC.
    - **Branch Prediction:** Incorrect guesses about which code path to execute can introduce pipeline stalls.
    - **Out-of-Order Execution:** Modern CPUs can dynamically reorder instructions to improve IPC.

## Million Instructions Per Second (MIPS)

- **Definition:** An older performance metric gauging how many millions of instructions a CPU can execute in one second.
- **Significance:**
    - Provides a rough idea of raw processing potential.
- **Limitations:**
    - Ignores IPC differences across architectures (a CPU with lower MIPS but higher IPC can be faster).
    - Instruction complexity has evolved; not all "instructions" take equal time.
    - Modern performance metrics are far more relevant.

## Cycles Per Instruction (CPI)

- **Definition:** The average number of clock cycles required to execute a single instruction.
- **Relationship with IPC:** CPI is the inverse of IPC (CPI = 1 / IPC).
- **Significance:**
    - Highlights bottlenecks in instruction execution. Lower CPI is desirable.
- **Factors affecting CPI:** Similar to those affecting IPC (instruction dependencies, branch mispredictions, memory access latency).


## Throughput

- **Definition:** The amount of work a computer system completes in a given time frame. Can be measured in tasks per second, instructions per second, or other relevant units.
- **Significance:**
    - Offers a high-level performance measure for real-world workloads.
- **Factors Affecting Throughput:**
    - Clock speed, IPC, core count, memory bandwidth, I/O speeds, workload characteristics.

## Latency

- **Definition:** Time delay between a request for data or an instruction execution and when the result becomes available.
- **Types:**
    - **Memory Latency:** Time taken to access data in RAM (influenced by RAM speed and CAS latency).
    - **Instruction Latency:** Time for a specific instruction to complete.
    - **Network Latency:** Delay in data transmission over networks.
- **Significance:**
    - High latency can create bottlenecks, even if throughput is good.
    - Crucial for real-time or interactive applications.

## Cache Hit and Miss Rates

- **Definition:**
    - **Cache Hit:** Requested data is found in the faster cache memory.
    - **Cache Miss:** Data is not in the cache, must be fetched from slower main memory.
- **Significance:**
    - Cache hit rates directly influence performance – higher hit rates mean less waiting for data.
- **Factors Affecting Hit/Miss Rates:**
    - Cache size, cache organization, data access patterns of the program.

## Memory Bandwidth

- **Definition:** The maximum rate at which data can be transferred between the CPU and main memory (RAM). Typically measured in gigabytes per second (GB/s).
- **Significance:**
    - A critical bottleneck for data-intensive applications that work with large datasets.
    - High memory bandwidth is essential to keep the CPU fed with data, preventing it from waiting idle.
- **Factors Affecting Memory Bandwidth:**
    - **Memory Type:** DDR4, DDR5, GDDR6, etc. Newer standards offer higher bandwidth
    - **Memory Modules:** The number of memory channels (dual-channel vs. quad-channel)
    - **Memory Frequency:** Higher clock speeds directly increase bandwidth.
- **Measurement:** Benchmarks specifically designed to measure memory read/write bandwidth.

## Power Consumption

- **Definition:** The amount of electrical power a computer system consumes. Measured in watts (W).
- **Significance:**
    - **Operational Costs:** Especially for data centers or large computing clusters, lower power consumption reduces electricity costs.
    - **Thermal Design:** Power consumption translates to heat output. Efficient designs with low power consumption are easier to cool.
    - **Mobile Devices:** Key for maximizing battery life in laptops, smartphones, etc.
- **Factors Affecting Power Consumption:**
    - **CPU and GPU Architecture:** More efficient architectures and smaller manufacturing processes (e.g., 7nm vs. 14nm) lead to lower power consumption.
    - **Workload:** Computationally demanding tasks significantly increase power usage.
    - **Power Management:** Technologies like dynamic voltage and frequency scaling (DVFS) adjust power states for efficiency.

## Floating-Point Operations Per Second (FLOPS)

- **Definition:** A measure of the number of floating-point calculations a processor can perform per second. Used especially for scientific and high-performance computing (HPC).
- **Significance:**
    - Indicates raw computational power for workloads involving floating-point arithmetic: simulations, machine learning, 3D graphics, etc.
- **Types:**
    - **Single Precision (FP32):** 32-bit floating-point calculations - common in machine learning.
    - **Double Precision (FP64):** 64-bit floating-point calculations – important for scientific simulations requiring high accuracy.
- **Factors Affecting FLOPS**
    - **Specialized Hardware Accelerators:** GPUs and TPUs excel at parallel floating-point computations.
    - **FLOPS per Watt:** A measure of computational efficiency taking power into account.

## Branch Prediction Accuracy

- **Definition:** The percentage of times a CPU correctly predicts the outcome of a conditional branch (e.g., if-else statements) in a program's code.
- **Significance:**
    - Incorrect branch predictions introduce delays as the pipeline needs to be flushed and refilled with the correct instructions.
    - Good branch prediction is crucial for maintaining a smooth flow of instructions in modern superscalar CPUs.
- **Techniques:**
    - **Static Prediction:** Simple prediction based on fixed heuristics.
    - **Dynamic Prediction:** Using past behavior patterns (branch history tables, pattern history tables).
    - **Neural Branch Predictors:** New research using machine learning models for prediction.

## Scalability

- **Definition:** The ability of a system (hardware or software) to maintain or improve performance when the workload increases or more resources (e.g., CPU cores) are added.
- **Types:**
    - **Strong Scaling:** Performance improves proportionally to added resources (ideal)
    - **Weak Scaling:** Performance improves but the efficiency gain diminishes with more resources.
- **Challenges to Scalability:**
    - **Amdahl's Law:** The impact of parallelizable vs. sequential portions of code.
    - **Synchronization Overheads:** Coordination between threads/processes
    - **Memory Contention:** Bandwidth limitations when many cores access memory.